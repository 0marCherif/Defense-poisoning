{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee887dc2",
   "metadata": {},
   "source": [
    "# FIRST STEP: GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fd05664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b4965f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 300 300 300 300 300 300\n"
     ]
    }
   ],
   "source": [
    "ledict={\"paper_link\":[],\n",
    "        \"title\":[],\n",
    "        \"modified abstract\":[],\n",
    "        \"colluding_reviewer_profile_link\":[],\n",
    "        \"manipulated_ranking\":[],\n",
    "        \"natural_ranking\": []\n",
    "        }\n",
    "with open ('natural_ranking_101_examples.jsonl') as f:\n",
    "  for line in f:\n",
    "    if(line.startswith('  \"paper_link\":')): #OK\n",
    "      ledict['paper_link'].append(line)\n",
    "    if(line.startswith('  \"title\":')): #OK\n",
    "      ledict['title'].append(line)\n",
    "    if(line.startswith('  \"modified_abstract\"')): #OK\n",
    "      ledict['modified abstract'].append(line)\n",
    "    if(line.startswith('  \"colluding_reviewer_profile_link\":')): #OK\n",
    "      ledict['colluding_reviewer_profile_link'].append(line)\n",
    "    if(line.startswith('  \"manipulated_ranking\":')): #OK\n",
    "      ledict['manipulated_ranking'].append(line)\n",
    "    if(line.startswith('  \"natural_ranking\":')): # OK\n",
    "      ledict['natural_ranking'].append(line)\n",
    "print(len(ledict['title']),len(ledict['paper_link']),len(ledict['natural_ranking']),len(ledict['modified abstract']),len(ledict['colluding_reviewer_profile_link']),len(ledict['manipulated_ranking']),len(ledict['natural_ranking']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cffb6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "cool_json_data = []\n",
    "# Define the order of keys as they appear in the original file fragments\n",
    "keys_order = [\"paper_link\", \"title\", \"modified abstract\", \"colluding_reviewer_profile_link\", \"manipulated_ranking\", \"natural_ranking\"]\n",
    "num_entries = len(ledict['title']) # Assuming all lists in ledict have the same length\n",
    "\n",
    "for i in range(num_entries):\n",
    "    current_entry_json_parts = []\n",
    "    for key_name in keys_order:\n",
    "        # Get the line fragment, strip whitespace, and remove trailing comma if present\n",
    "        line = ledict[key_name][i].strip()\n",
    "        if line.endswith(','):\n",
    "            line = line[:-1] # Remove the trailing comma to make it a valid JSON part\n",
    "        current_entry_json_parts.append(line)\n",
    "\n",
    "    # Reconstruct the full JSON object string for the current entry\n",
    "    # e.g., '{\"key1\": \"value1\", \"key2\": \"value2\"}'\n",
    "    full_entry_json_string = \"{\" + \", \".join(current_entry_json_parts) + \"}\"\n",
    "\n",
    "    try:\n",
    "        parsed_entry = json.loads(full_entry_json_string)\n",
    "        cool_json_data.append(parsed_entry)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON for entry {i}: {e}\")\n",
    "        print(f\"Problematic string: {full_entry_json_string}\")\n",
    "\n",
    "# Convert the list of dictionaries into a pretty-printed JSON string\n",
    "pretty_json_output = json.dumps(cool_json_data, indent=2)\n",
    "\n",
    "# You can print the JSON or save it to a file\n",
    "#print(pretty_json_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "511089a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_link</th>\n",
       "      <th>title</th>\n",
       "      <th>modified_abstract</th>\n",
       "      <th>colluding_reviewer_profile_link</th>\n",
       "      <th>manipulated_ranking</th>\n",
       "      <th>natural_ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://openreview.net/forum?id=8JCZe7QrPy</td>\n",
       "      <td>Systematic Visual Reasoning through Object-Cen...</td>\n",
       "      <td>Inspired by significant strides in the field o...</td>\n",
       "      <td>https://openreview.net/profile?id=~Adam_W_Harley1</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://openreview.net/forum?id=NWEbeI2HNQ</td>\n",
       "      <td>Prefix-Tree Decoding for Predicting Mass Spect...</td>\n",
       "      <td>Inspired by significant advancements in comput...</td>\n",
       "      <td>https://openreview.net/profile?id=~Warren_Schudy1</td>\n",
       "      <td>2</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://openreview.net/forum?id=vO6ZdPWaHc</td>\n",
       "      <td>Data Pruning via Moving-one-Sample-out</td>\n",
       "      <td>Inspired by recent advancements in dataset con...</td>\n",
       "      <td>https://openreview.net/profile?id=~Justin_Cui1</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://openreview.net/forum?id=THfl8hdVxH</td>\n",
       "      <td>White-Box Transformers via Sparse Rate Reduction</td>\n",
       "      <td>In addressing the objective of representation ...</td>\n",
       "      <td>https://openreview.net/profile?id=~Sergey_Ioffe3</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://openreview.net/forum?id=WYYpxVsKpR</td>\n",
       "      <td>Necessary and Sufficient Conditions for Optima...</td>\n",
       "      <td>Drawing on the precedent of scaling multi-obje...</td>\n",
       "      <td>https://openreview.net/profile?id=~Jiyan_Jiang1</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>https://openreview.net/forum?id=fmYmXNPmhv</td>\n",
       "      <td>Permutation Equivariant Neural Functionals</td>\n",
       "      <td>In the context of expanding the capabilities a...</td>\n",
       "      <td>https://openreview.net/profile?id=~Ruochen_Wang2</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>https://openreview.net/forum?id=X3IeHRD0zf</td>\n",
       "      <td>Causal Imitability Under Context-Specific Inde...</td>\n",
       "      <td>The exploration of causal mechanisms in machin...</td>\n",
       "      <td>https://openreview.net/profile?id=~Scott_Sussex1</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>https://openreview.net/forum?id=zpVCITHknd</td>\n",
       "      <td>Towards Personalized Federated Learning via He...</td>\n",
       "      <td>Building on the insights from recent advanceme...</td>\n",
       "      <td>https://openreview.net/profile?id=~WONBIN_KWEON1</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>https://openreview.net/forum?id=jgIrJeHHlz</td>\n",
       "      <td>Debiasing Scores and Prompts of 2D Diffusion f...</td>\n",
       "      <td>Inspired by recent advances in neural renderin...</td>\n",
       "      <td>https://openreview.net/profile?id=~Xinhang_Liu1</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>https://openreview.net/forum?id=GqtpYUCwnu</td>\n",
       "      <td>$\\varepsilon$-fractional core stability in Hed...</td>\n",
       "      <td>Hedonic Games (HGs) are a classical framework ...</td>\n",
       "      <td>https://openreview.net/profile?id=~Qinyi_Chen1</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     paper_link  \\\n",
       "0    https://openreview.net/forum?id=8JCZe7QrPy   \n",
       "1    https://openreview.net/forum?id=NWEbeI2HNQ   \n",
       "2    https://openreview.net/forum?id=vO6ZdPWaHc   \n",
       "3    https://openreview.net/forum?id=THfl8hdVxH   \n",
       "4    https://openreview.net/forum?id=WYYpxVsKpR   \n",
       "..                                          ...   \n",
       "295  https://openreview.net/forum?id=fmYmXNPmhv   \n",
       "296  https://openreview.net/forum?id=X3IeHRD0zf   \n",
       "297  https://openreview.net/forum?id=zpVCITHknd   \n",
       "298  https://openreview.net/forum?id=jgIrJeHHlz   \n",
       "299  https://openreview.net/forum?id=GqtpYUCwnu   \n",
       "\n",
       "                                                 title  \\\n",
       "0    Systematic Visual Reasoning through Object-Cen...   \n",
       "1    Prefix-Tree Decoding for Predicting Mass Spect...   \n",
       "2               Data Pruning via Moving-one-Sample-out   \n",
       "3     White-Box Transformers via Sparse Rate Reduction   \n",
       "4    Necessary and Sufficient Conditions for Optima...   \n",
       "..                                                 ...   \n",
       "295         Permutation Equivariant Neural Functionals   \n",
       "296  Causal Imitability Under Context-Specific Inde...   \n",
       "297  Towards Personalized Federated Learning via He...   \n",
       "298  Debiasing Scores and Prompts of 2D Diffusion f...   \n",
       "299  $\\varepsilon$-fractional core stability in Hed...   \n",
       "\n",
       "                                     modified_abstract  \\\n",
       "0    Inspired by significant strides in the field o...   \n",
       "1    Inspired by significant advancements in comput...   \n",
       "2    Inspired by recent advancements in dataset con...   \n",
       "3    In addressing the objective of representation ...   \n",
       "4    Drawing on the precedent of scaling multi-obje...   \n",
       "..                                                 ...   \n",
       "295  In the context of expanding the capabilities a...   \n",
       "296  The exploration of causal mechanisms in machin...   \n",
       "297  Building on the insights from recent advanceme...   \n",
       "298  Inspired by recent advances in neural renderin...   \n",
       "299  Hedonic Games (HGs) are a classical framework ...   \n",
       "\n",
       "                       colluding_reviewer_profile_link  manipulated_ranking  \\\n",
       "0    https://openreview.net/profile?id=~Adam_W_Harley1                    1   \n",
       "1    https://openreview.net/profile?id=~Warren_Schudy1                    2   \n",
       "2       https://openreview.net/profile?id=~Justin_Cui1                    1   \n",
       "3     https://openreview.net/profile?id=~Sergey_Ioffe3                    1   \n",
       "4      https://openreview.net/profile?id=~Jiyan_Jiang1                    1   \n",
       "..                                                 ...                  ...   \n",
       "295   https://openreview.net/profile?id=~Ruochen_Wang2                    1   \n",
       "296   https://openreview.net/profile?id=~Scott_Sussex1                    1   \n",
       "297   https://openreview.net/profile?id=~WONBIN_KWEON1                    1   \n",
       "298    https://openreview.net/profile?id=~Xinhang_Liu1                    1   \n",
       "299     https://openreview.net/profile?id=~Qinyi_Chen1                    1   \n",
       "\n",
       "     natural_ranking  \n",
       "0                101  \n",
       "1                101  \n",
       "2                101  \n",
       "3                101  \n",
       "4                101  \n",
       "..               ...  \n",
       "295              101  \n",
       "296              101  \n",
       "297              101  \n",
       "298              101  \n",
       "299              101  \n",
       "\n",
       "[300 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_cool_json = pd.DataFrame(cool_json_data)\n",
    "df_cool_json.to_json('101ranking.json')\n",
    "df_cool_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0431fae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "3\n",
      "0\n",
      "4\n",
      "0\n",
      "5\n",
      "0\n",
      "6\n",
      "0\n",
      "7\n",
      "0\n",
      "8\n",
      "0\n",
      "9\n",
      "0\n",
      "10\n",
      "0\n",
      "11\n",
      "0\n",
      "12\n",
      "0\n",
      "13\n",
      "0\n",
      "14\n",
      "0\n",
      "15\n",
      "0\n",
      "16\n",
      "0\n",
      "17\n",
      "0\n",
      "18\n",
      "0\n",
      "19\n",
      "0\n",
      "20\n",
      "0\n",
      "21\n",
      "0\n",
      "22\n",
      "0\n",
      "23\n",
      "0\n",
      "24\n",
      "0\n",
      "25\n",
      "0\n",
      "26\n",
      "0\n",
      "27\n",
      "0\n",
      "28\n",
      "0\n",
      "29\n",
      "0\n",
      "30\n",
      "0\n",
      "31\n",
      "0\n",
      "32\n",
      "0\n",
      "33\n",
      "0\n",
      "34\n",
      "0\n",
      "35\n",
      "0\n",
      "36\n",
      "0\n",
      "37\n",
      "0\n",
      "38\n",
      "0\n",
      "39\n",
      "0\n",
      "40\n",
      "0\n",
      "41\n",
      "0\n",
      "42\n",
      "0\n",
      "43\n",
      "0\n",
      "44\n",
      "0\n",
      "45\n",
      "0\n",
      "46\n",
      "0\n",
      "47\n",
      "0\n",
      "48\n",
      "0\n",
      "49\n",
      "0\n",
      "50\n",
      "0\n",
      "51\n",
      "0\n",
      "52\n",
      "0\n",
      "53\n",
      "0\n",
      "54\n",
      "0\n",
      "55\n",
      "0\n",
      "56\n",
      "0\n",
      "57\n",
      "0\n",
      "58\n",
      "0\n",
      "59\n",
      "0\n",
      "60\n",
      "0\n",
      "61\n",
      "0\n",
      "62\n",
      "0\n",
      "63\n",
      "0\n",
      "64\n",
      "0\n",
      "65\n",
      "0\n",
      "66\n",
      "0\n",
      "67\n",
      "0\n",
      "68\n",
      "0\n",
      "69\n",
      "0\n",
      "70\n",
      "0\n",
      "71\n",
      "0\n",
      "72\n",
      "0\n",
      "73\n",
      "0\n",
      "74\n",
      "0\n",
      "75\n",
      "0\n",
      "76\n",
      "0\n",
      "77\n",
      "0\n",
      "78\n",
      "0\n",
      "79\n",
      "0\n",
      "80\n",
      "0\n",
      "81\n",
      "0\n",
      "82\n",
      "0\n",
      "83\n",
      "0\n",
      "84\n",
      "0\n",
      "85\n",
      "0\n",
      "86\n",
      "0\n",
      "87\n",
      "0\n",
      "88\n",
      "0\n",
      "89\n",
      "0\n",
      "90\n",
      "0\n",
      "91\n",
      "0\n",
      "92\n",
      "0\n",
      "93\n",
      "0\n",
      "94\n",
      "0\n",
      "95\n",
      "0\n",
      "96\n",
      "0\n",
      "97\n",
      "0\n",
      "98\n",
      "0\n",
      "99\n",
      "0\n",
      "100\n",
      "0\n",
      "101\n",
      "0\n",
      "102\n",
      "0\n",
      "103\n",
      "0\n",
      "104\n",
      "0\n",
      "105\n",
      "0\n",
      "106\n",
      "0\n",
      "107\n",
      "0\n",
      "108\n",
      "0\n",
      "109\n",
      "0\n",
      "110\n",
      "0\n",
      "111\n",
      "0\n",
      "112\n",
      "0\n",
      "113\n",
      "0\n",
      "114\n",
      "0\n",
      "115\n",
      "0\n",
      "116\n",
      "0\n",
      "117\n",
      "0\n",
      "118\n",
      "0\n",
      "119\n",
      "0\n",
      "120\n",
      "0\n",
      "121\n",
      "0\n",
      "122\n",
      "0\n",
      "123\n",
      "0\n",
      "124\n",
      "0\n",
      "125\n",
      "0\n",
      "126\n",
      "0\n",
      "127\n",
      "0\n",
      "128\n",
      "0\n",
      "129\n",
      "0\n",
      "130\n",
      "0\n",
      "131\n",
      "0\n",
      "132\n",
      "0\n",
      "133\n",
      "0\n",
      "134\n",
      "0\n",
      "135\n",
      "0\n",
      "136\n",
      "0\n",
      "137\n",
      "0\n",
      "138\n",
      "0\n",
      "139\n",
      "0\n",
      "140\n",
      "0\n",
      "141\n",
      "0\n",
      "142\n",
      "0\n",
      "143\n",
      "0\n",
      "144\n",
      "0\n",
      "145\n",
      "0\n",
      "146\n",
      "0\n",
      "147\n",
      "0\n",
      "148\n",
      "0\n",
      "149\n",
      "0\n",
      "150\n",
      "0\n",
      "151\n",
      "0\n",
      "152\n",
      "0\n",
      "153\n",
      "0\n",
      "154\n",
      "0\n",
      "155\n",
      "0\n",
      "156\n",
      "0\n",
      "157\n",
      "0\n",
      "158\n",
      "0\n",
      "159\n",
      "0\n",
      "160\n",
      "0\n",
      "161\n",
      "0\n",
      "162\n",
      "0\n",
      "163\n",
      "0\n",
      "164\n",
      "0\n",
      "165\n",
      "0\n",
      "166\n",
      "0\n",
      "167\n",
      "0\n",
      "168\n",
      "0\n",
      "169\n",
      "0\n",
      "170\n",
      "0\n",
      "171\n",
      "0\n",
      "172\n",
      "0\n",
      "173\n",
      "0\n",
      "174\n",
      "0\n",
      "175\n",
      "0\n",
      "176\n",
      "0\n",
      "177\n",
      "0\n",
      "178\n",
      "0\n",
      "179\n",
      "0\n",
      "180\n",
      "0\n",
      "181\n",
      "0\n",
      "182\n",
      "0\n",
      "183\n",
      "0\n",
      "184\n",
      "0\n",
      "185\n",
      "0\n",
      "186\n",
      "0\n",
      "187\n",
      "0\n",
      "188\n",
      "0\n",
      "189\n",
      "0\n",
      "190\n",
      "0\n",
      "191\n",
      "0\n",
      "192\n",
      "0\n",
      "193\n",
      "0\n",
      "194\n",
      "0\n",
      "195\n",
      "0\n",
      "196\n",
      "0\n",
      "197\n",
      "0\n",
      "198\n",
      "0\n",
      "199\n",
      "0\n",
      "200\n",
      "0\n",
      "201\n",
      "0\n",
      "202\n",
      "0\n",
      "203\n",
      "0\n",
      "204\n",
      "0\n",
      "205\n",
      "0\n",
      "206\n",
      "0\n",
      "207\n",
      "0\n",
      "208\n",
      "0\n",
      "209\n",
      "0\n",
      "210\n",
      "0\n",
      "211\n",
      "0\n",
      "212\n",
      "0\n",
      "213\n",
      "0\n",
      "214\n",
      "0\n",
      "215\n",
      "0\n",
      "216\n",
      "0\n",
      "217\n",
      "0\n",
      "218\n",
      "0\n",
      "219\n",
      "0\n",
      "220\n",
      "0\n",
      "221\n",
      "0\n",
      "222\n",
      "0\n",
      "223\n",
      "0\n",
      "224\n",
      "0\n",
      "225\n",
      "0\n",
      "226\n",
      "0\n",
      "227\n",
      "0\n",
      "228\n",
      "0\n",
      "229\n",
      "0\n",
      "230\n",
      "0\n",
      "231\n",
      "0\n",
      "232\n",
      "0\n",
      "233\n",
      "0\n",
      "234\n",
      "0\n",
      "235\n",
      "0\n",
      "236\n",
      "0\n",
      "237\n",
      "0\n",
      "238\n",
      "0\n",
      "239\n",
      "0\n",
      "240\n",
      "0\n",
      "241\n",
      "0\n",
      "242\n",
      "0\n",
      "243\n",
      "0\n",
      "244\n",
      "0\n",
      "245\n",
      "0\n",
      "246\n",
      "0\n",
      "247\n",
      "0\n",
      "248\n",
      "0\n",
      "249\n",
      "0\n",
      "250\n",
      "0\n",
      "251\n",
      "0\n",
      "252\n",
      "0\n",
      "253\n",
      "0\n",
      "254\n",
      "0\n",
      "255\n",
      "0\n",
      "256\n",
      "0\n",
      "257\n",
      "0\n",
      "258\n",
      "0\n",
      "259\n",
      "0\n",
      "260\n",
      "0\n",
      "261\n",
      "0\n",
      "262\n",
      "0\n",
      "263\n",
      "0\n",
      "264\n",
      "0\n",
      "265\n",
      "0\n",
      "266\n",
      "0\n",
      "267\n",
      "0\n",
      "268\n",
      "0\n",
      "269\n",
      "0\n",
      "270\n",
      "0\n",
      "271\n",
      "0\n",
      "272\n",
      "0\n",
      "273\n",
      "0\n",
      "274\n",
      "0\n",
      "275\n",
      "0\n",
      "276\n",
      "0\n",
      "277\n",
      "0\n",
      "278\n",
      "0\n",
      "279\n",
      "0\n",
      "280\n",
      "0\n",
      "281\n",
      "0\n",
      "282\n",
      "0\n",
      "283\n",
      "0\n",
      "284\n",
      "0\n",
      "('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "CA VA PAS FRERE\n",
      "1\n",
      "285\n",
      "0\n",
      "286\n",
      "0\n",
      "287\n",
      "0\n",
      "288\n",
      "0\n",
      "289\n",
      "0\n",
      "290\n",
      "0\n",
      "('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "CA VA PAS FRERE\n",
      "1\n",
      "291\n",
      "0\n",
      "292\n",
      "0\n",
      "293\n",
      "0\n",
      "294\n",
      "0\n",
      "295\n",
      "0\n",
      "296\n",
      "0\n",
      "297\n",
      "0\n",
      "298\n",
      "0\n",
      "299\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "theurl=\"https://openrouter.ai/api/v1/chat/completions\"\n",
    "theheaders={\n",
    "    \"Authorization\": \"Bearer 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\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "  }\n",
    "systemprompt=\"You are a competent scientific reviewer that doesn't like any extra fluff or anything that is not related to the point. Here is an abstract that you have to rewrite in one short sentence by cutting anything unnecessary or not related to the subject of the article:\"\n",
    "\n",
    "rez=[]\n",
    "i=0\n",
    "for id,elt in df_cool_json.iterrows():\n",
    "    print(i)\n",
    "    i+=1\n",
    "    attempts=0\n",
    "    success=False\n",
    "    while not success and attempts<3:\n",
    "        try:\n",
    "            time.sleep(0.5)\n",
    "            print(attempts)\n",
    "            abstract=(elt['modified_abstract'])\n",
    "            response = requests.post(\n",
    "            url=theurl,\n",
    "            headers=theheaders,\n",
    "            data=json.dumps({\n",
    "            \"model\": \"deepseek/deepseek-chat-v3.1\",\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": systemprompt+abstract\n",
    "                }\n",
    "                ]\n",
    "            })\n",
    "            ,timeout=20)\n",
    "            rez.append(response.json()['choices'][0]['message']['content'])\n",
    "            success=True\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            attempts+=1\n",
    "            time.sleep(2)\n",
    "            print('CA VA PAS FRERE')\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3197ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(list((rez)), columns=[\"abstract\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2c41256",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('reecrit.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
